{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f0eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either you can store the  OpenAI key in the “OPENAI_API_KEY” environment variable.\n",
    "# or pass it here as below from a config.ini\n",
    "import configparser\n",
    "workingFolder=r'C:\\Users\\jfrancis\\AI Journey\\Gen AI'\n",
    "# Read the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(workingFolder+'\\\\config.ini')\n",
    "OPENAI_API_KEY=config.get('General','OPENAI_API_KEY')\n",
    "ACTIVELOOP_TOKEN=config.get('General','ACTIVELOOP_TOKEN')\n",
    "ACTIVELOOP_ORG_ID=config.get('General','ACTIVELOOP_ORG_ID')\n",
    "HUGGINGFACEHUB_API_TOKEN=config.get('General','HUGGINGFACEHUB_API_TOKEN')\n",
    "GOOGLE_API_KEY=config.get('General','GOOGLE_API_KEY')\n",
    "GOOGLE_CSE_ID=config.get('General','GOOGLE_CSE_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5b4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62504cd0",
   "metadata": {},
   "source": [
    "# Workflow for Creating Knowledge Graphs from Textual Data\n",
    "\n",
    "Here’s what we are going to do in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb0e803",
   "metadata": {},
   "source": [
    "<img src=\"https://images.spr.so/cdn-cgi/imagedelivery/j42No7y-dcokJuNgXeA0ig/5b5cf0f6-85a3-447a-bba7-5d1e6d36874e/Untitled_Diagram_(1)/w=1920,quality=80\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7859db9",
   "metadata": {},
   "source": [
    "#### Building a Knowledge Graph\n",
    "\n",
    "The process of building a knowledge graph usually consists of two sequential steps:\n",
    "\n",
    "    Named Entity Recognition (NER): This step involves extracting entities from the text, which will eventually become the nodes of the knowledge graph.\n",
    "    Relation Classification (RC): In this step, relations between entities are extracted, forming the edges of the knowledge graph.\n",
    "\n",
    "Then, the knowledge graph is commonly visualized using libraries such as pyvis .\n",
    "\n",
    "Typically the process of creating a knowledge base from the text can be enhanced by incorporating additional steps, such as:\n",
    "\n",
    "    Entity Linking: This involves normalizing entities to the same entity, such as “Napoleon” and “Napoleon Bonapart.” This is usually done by linking them to a canonical source, like a Wikipedia page.\n",
    "    Source Tracking: Keeping track of the origin of each relation, such as the article URL and text span. Keeping track of the sources allows us to gather insights into the reliability of the extracted information (e.g., a relation is accurate if it can be extracted from several sources considered accurate).\n",
    "\n",
    "In this project, we’ll do the Named Entity Recognition and Relation Classification tasks simultaneously with an appropriate prompt. This joint task is commonly called Relation Extraction (RE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcbbe52",
   "metadata": {},
   "source": [
    "#### Building a Knowledge Graph with LangChain\n",
    "\n",
    "To demonstrate an example of using a prompt to extract relations from the text in LangChain, we can use the following  KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT prompt as a starting point. This prompt is designed to extract knowledge triples (subject, predicate, and object) from a given text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b23840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (Paris, is the capital and most populous city of, France)<|>(Eiffel Tower, is a famous landmark in, Paris)\n",
      "END OF EXAMPLE\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER\n",
    "\n",
    "# Prompt template for knowledge triple extraction\n",
    "_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE = (\n",
    "    \"You are a networked intelligence helping a human track knowledge triples\"\n",
    "    \" about all relevant people, things, concepts, etc. and integrating\"\n",
    "    \" them with your knowledge stored within your weights\"\n",
    "    \" as well as that stored in a knowledge graph.\"\n",
    "    \" Extract all of the knowledge triples from the text.\"\n",
    "    \" A knowledge triple is a clause that contains a subject, a predicate,\"\n",
    "    \" and an object. The subject is the entity being described,\"\n",
    "    \" the predicate is the property of the subject that is being\"\n",
    "    \" described, and the object is the value of the property.\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\n\"\n",
    "    f\"Output: (Nevada, is a, state){KG_TRIPLE_DELIMITER}(Nevada, is in, US)\"\n",
    "    f\"{KG_TRIPLE_DELIMITER}(Nevada, is the number 1 producer of, gold)\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"I'm going to the store.\\n\\n\"\n",
    "    \"Output: NONE\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\n\"\n",
    "    f\"Output: (Descartes, likes to drive, antique scooters){KG_TRIPLE_DELIMITER}(Descartes, plays, mandolin)\\n\"\n",
    "    \"END OF EXAMPLE\\n\\n\"\n",
    "    \"EXAMPLE\\n\"\n",
    "    \"{text}\"\n",
    "    \"Output:\"\n",
    ")\n",
    "\n",
    "KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE,\n",
    ")\n",
    "\n",
    "# Make sure to save your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "# Instantiate the OpenAI model\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0.9)\n",
    "\n",
    "# Create an LLMChain using the knowledge triple extraction prompt\n",
    "chain = LLMChain(llm=llm, prompt=KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT)\n",
    "\n",
    "# Run the chain with the specified text\n",
    "text = \"The city of Paris is the capital and most populous city of France. The Eiffel Tower is a famous landmark in Paris.\"\n",
    "triples = chain.run(text)\n",
    "\n",
    "print(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586c3bd0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eabe6442",
   "metadata": {},
   "source": [
    "In the previous code, we used the prompt to extract relation triplets from text using few-shot examples. We'll then parse the generated triplets and collect them into a list.\n",
    "\n",
    "Here, triples_list will contain the knowledge triplets extracted from the text. We need to parse the response and collect the triplets into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121f902c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' (Paris, is the capital and most populous city of, France)', '(Eiffel Tower, is a famous landmark in, Paris)\\nEND OF EXAMPLE']\n"
     ]
    }
   ],
   "source": [
    "def parse_triples(response, delimiter=KG_TRIPLE_DELIMITER):\n",
    "    if not response:\n",
    "        return []\n",
    "    return response.split(delimiter)\n",
    "\n",
    "triples_list = parse_triples(triples)\n",
    "\n",
    "# Print the extracted relation triplets\n",
    "print(triples_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7718c3d",
   "metadata": {},
   "source": [
    "#### Knowledge Graph Visualization\n",
    "\n",
    "The NetworkX library is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. It provides various graph generators, random graphs, and synthetic networks, along with the benefits of Python's fast prototyping, ease of teaching, and multi-platform support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b565e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "knowledge_graph.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"knowledge_graph.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x19e00585d50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "# Create a NetworkX graph from the extracted relation triplets\n",
    "def create_graph_from_triplets(triplets):\n",
    "    G = nx.DiGraph()\n",
    "    for triplet in triplets:\n",
    "        subject, predicate, obj = triplet.strip().split(',')\n",
    "        G.add_edge(subject.strip(), obj.strip(), label=predicate.strip())\n",
    "    return G\n",
    "\n",
    "# Convert the NetworkX graph to a PyVis network\n",
    "def nx_to_pyvis(networkx_graph):\n",
    "    pyvis_graph = Network(notebook=True)\n",
    "    for node in networkx_graph.nodes():\n",
    "        pyvis_graph.add_node(node)\n",
    "    for edge in networkx_graph.edges(data=True):\n",
    "        pyvis_graph.add_edge(edge[0], edge[1], label=edge[2][\"label\"])\n",
    "    return pyvis_graph\n",
    "\n",
    "triplets = [t.strip() for t in triples_list if t.strip()]\n",
    "graph = create_graph_from_triplets(triplets)\n",
    "pyvis_network = nx_to_pyvis(graph)\n",
    "\n",
    "# Customize the appearance of the graph\n",
    "pyvis_network.toggle_hide_edges_on_drag(True)\n",
    "pyvis_network.toggle_physics(False)\n",
    "pyvis_network.set_edge_smooth('discrete')\n",
    "\n",
    "# Show the interactive knowledge graph visualization\n",
    "pyvis_network.show('knowledge_graph.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_llm",
   "language": "python",
   "name": "env_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
