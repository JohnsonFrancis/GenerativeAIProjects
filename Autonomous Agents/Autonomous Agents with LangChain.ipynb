{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9691b12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-11-27T12:11:43.899667+05:30\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.5\n",
      "IPython version      : 8.15.0\n",
      "\n",
      "Compiler    : MSC v.1916 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 140 Stepping 1, GenuineIntel\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "109c875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either you can store the  OpenAI key in the “OPENAI_API_KEY” environment variable.\n",
    "# or pass it here as below from a config.ini\n",
    "import configparser\n",
    "workingFolder='C:\\\\Users\\\\jfrancis\\\\AI Journey\\\\Gen AI\\\\'\n",
    "# Read the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read(workingFolder+'\\\\config.ini')\n",
    "OPENAI_API_KEY=config.get('General','OPENAI_API_KEY')\n",
    "ACTIVELOOP_TOKEN=config.get('General','ACTIVELOOP_TOKEN')\n",
    "ACTIVELOOP_ORG_ID=config.get('General','ACTIVELOOP_ORG_ID')\n",
    "HUGGINGFACEHUB_API_TOKEN=config.get('General','HUGGINGFACEHUB_API_TOKEN')\n",
    "GOOGLE_API_KEY=config.get('General','GOOGLE_API_KEY')\n",
    "GOOGLE_CSE_ID=config.get('General','GOOGLE_CSE_ID')\n",
    "COHERE_API_KEY=config.get('General','COHERE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b21d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the token from Hugginface/Active loop website before this. Now we are taking from the config.ini\n",
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ[\"ACTIVELOOP_TOKEN\"] = ACTIVELOOP_TOKEN\n",
    "# create Deep Lake dataset\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = ACTIVELOOP_ORG_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922897a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests : 2.31.0\n",
      "deeplake : 3.8.6\n",
      "newspaper: 0.2.8\n",
      "langchain: 0.0.336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "import newspaper\n",
    "import requests\n",
    "import deeplake\n",
    "%watermark --iversions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c05e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scrape several Artificial Intelligence news\n",
    "\n",
    "import requests\n",
    "from newspaper import Article # https://github.com/codelucas/newspaper\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = [\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/23/meta-open-source-speech-ai-models-support-over-1100-languages/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/18/beijing-launches-campaign-against-ai-generated-misinformation/\"\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/eu-committees-green-light-ai-act/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/09/wozniak-warns-ai-will-power-next-gen-scams/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/09/infocepts-ceo-shashank-garg-on-the-da-market-shifts-and-impact-of-ai-on-data-analytics/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/26/ftc-chairwoman-no-ai-exemption-to-existing-laws/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/24/bill-gates-ai-teaching-kids-literacy-within-18-months/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/21/google-creates-new-ai-division-to-challenge-openai/\"\n",
    "]\n",
    "\n",
    "session = requests.Session()\n",
    "pages_content = [] # where we save the scraped articles\n",
    "\n",
    "for url in article_urls:\n",
    "    try:\n",
    "        time.sleep(2) # sleep two seconds for gentle scraping\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            article = Article(url)\n",
    "            article.download() # download HTML of webpage\n",
    "            article.parse() # parse HTML to extract the article text\n",
    "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching article at {url}: {e}\")\n",
    "\n",
    "#If an error occurs while fetching an article, we catch the exception and print\n",
    "#an error message. This ensures that even if one article fails to download,\n",
    "#the rest of the articles can still be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37d99d3",
   "metadata": {},
   "source": [
    "Then, we import the OpenAIEmbeddings class, which will be used to compute embeddings for our documents. We also import the Deep Lake class from the langchain.vectorstores module will serve as the storage for our documents and their embeddings. \n",
    "\n",
    "By setting up the Deep Lake instance with a specified dataset path and the embedding_function parameter set to the OpenAIEmbeddings instance, we establish a connection to Deep Lake and configure it to use the specified embedding model for computing document embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee638338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedding function is deprecated and will be removed in the future. Please use embedding instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "# We'll use an embedding model to compute our documents' embeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# We'll store the documents and their embeddings in the deep lake vector db\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "# Setup deep lake\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "my_activeloop_dataset_name = \"langchain_course_analysis_outline\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390f5e0",
   "metadata": {},
   "source": [
    "Next, we create an instance of RecursiveCharacterTextSplitter with specified chunk_size and chunk_overlap parameters. Then, we iterated over the pages_content and use the split_text method of the text_splitter to split each article text into chunks. These chunks are then appended to the all_texts list, resulting in a collection of smaller text chunks derived from the original articles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c76ee7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the article texts into small chunks\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "all_texts = []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        all_texts.append(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a612b5",
   "metadata": {},
   "source": [
    "Now we can add those chunks to the Deep Lake database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b177ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 94 embeddings in 1 batches of size 94:: 100%|███████████████████████████████████| 1/1 [00:45<00:00, 45.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://jfrancis/langchain_course_analysis_outline', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape      dtype  compression\n",
      "  -------    -------    -------    -------  ------- \n",
      "   text       text      (94, 1)      str     None   \n",
      " metadata     json      (94, 1)      str     None   \n",
      " embedding  embedding  (94, 1536)  float32   None   \n",
      "    id        text      (94, 1)      str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e7b21203-8cf0-11ee-b60b-401c83da435e',\n",
       " 'e7b21204-8cf0-11ee-98a7-401c83da435e',\n",
       " 'e7b21205-8cf0-11ee-b082-401c83da435e',\n",
       " 'e7b21206-8cf0-11ee-b8f9-401c83da435e',\n",
       " 'e7b21207-8cf0-11ee-9aea-401c83da435e',\n",
       " 'e7b21208-8cf0-11ee-8297-401c83da435e',\n",
       " 'e7b21209-8cf0-11ee-9092-401c83da435e',\n",
       " 'e7b2120a-8cf0-11ee-bdca-401c83da435e',\n",
       " 'e7b2120b-8cf0-11ee-a0b8-401c83da435e',\n",
       " 'e7b2120c-8cf0-11ee-9f19-401c83da435e',\n",
       " 'e7b2120d-8cf0-11ee-99ea-401c83da435e',\n",
       " 'e7b2120e-8cf0-11ee-bac4-401c83da435e',\n",
       " 'e7b2120f-8cf0-11ee-b229-401c83da435e',\n",
       " 'e7b21210-8cf0-11ee-b51c-401c83da435e',\n",
       " 'e7b21211-8cf0-11ee-9369-401c83da435e',\n",
       " 'e7b21212-8cf0-11ee-bdf0-401c83da435e',\n",
       " 'e7b21213-8cf0-11ee-9e80-401c83da435e',\n",
       " 'e7b21214-8cf0-11ee-96ea-401c83da435e',\n",
       " 'e7b21215-8cf0-11ee-a556-401c83da435e',\n",
       " 'e7b21216-8cf0-11ee-b910-401c83da435e',\n",
       " 'e7b21217-8cf0-11ee-ba1e-401c83da435e',\n",
       " 'e7b21218-8cf0-11ee-8dfa-401c83da435e',\n",
       " 'e7b21219-8cf0-11ee-a04c-401c83da435e',\n",
       " 'e7b2121a-8cf0-11ee-88e9-401c83da435e',\n",
       " 'e7b2121b-8cf0-11ee-9209-401c83da435e',\n",
       " 'e7b2121c-8cf0-11ee-88f1-401c83da435e',\n",
       " 'e7b237e4-8cf0-11ee-b05f-401c83da435e',\n",
       " 'e7b237e5-8cf0-11ee-8611-401c83da435e',\n",
       " 'e7b237e6-8cf0-11ee-a793-401c83da435e',\n",
       " 'e7b237e7-8cf0-11ee-b329-401c83da435e',\n",
       " 'e7b237e8-8cf0-11ee-9008-401c83da435e',\n",
       " 'e7b237e9-8cf0-11ee-bf2f-401c83da435e',\n",
       " 'e7b237ea-8cf0-11ee-ba39-401c83da435e',\n",
       " 'e7b237eb-8cf0-11ee-a215-401c83da435e',\n",
       " 'e7b237ec-8cf0-11ee-bee5-401c83da435e',\n",
       " 'e7b237ed-8cf0-11ee-ad21-401c83da435e',\n",
       " 'e7b237ee-8cf0-11ee-b3da-401c83da435e',\n",
       " 'e7b237ef-8cf0-11ee-a685-401c83da435e',\n",
       " 'e7b237f0-8cf0-11ee-b9bd-401c83da435e',\n",
       " 'e7b237f1-8cf0-11ee-8967-401c83da435e',\n",
       " 'e7b237f2-8cf0-11ee-93d9-401c83da435e',\n",
       " 'e7b237f3-8cf0-11ee-8652-401c83da435e',\n",
       " 'e7b237f4-8cf0-11ee-aeb5-401c83da435e',\n",
       " 'e7b237f5-8cf0-11ee-84b8-401c83da435e',\n",
       " 'e7b237f6-8cf0-11ee-b986-401c83da435e',\n",
       " 'e7b237f7-8cf0-11ee-b66e-401c83da435e',\n",
       " 'e7b237f8-8cf0-11ee-abc6-401c83da435e',\n",
       " 'e7b237f9-8cf0-11ee-9521-401c83da435e',\n",
       " 'e7b237fa-8cf0-11ee-9e37-401c83da435e',\n",
       " 'e7b237fb-8cf0-11ee-a3d3-401c83da435e',\n",
       " 'e7b237fc-8cf0-11ee-8671-401c83da435e',\n",
       " 'e7b237fd-8cf0-11ee-96a4-401c83da435e',\n",
       " 'e7b237fe-8cf0-11ee-9bc9-401c83da435e',\n",
       " 'e7b237ff-8cf0-11ee-943c-401c83da435e',\n",
       " 'e7b23800-8cf0-11ee-a718-401c83da435e',\n",
       " 'e7b23801-8cf0-11ee-a8fc-401c83da435e',\n",
       " 'e7b23802-8cf0-11ee-ba6e-401c83da435e',\n",
       " 'e7b23803-8cf0-11ee-8d16-401c83da435e',\n",
       " 'e7b23804-8cf0-11ee-bddc-401c83da435e',\n",
       " 'e7b23805-8cf0-11ee-a35c-401c83da435e',\n",
       " 'e7b23806-8cf0-11ee-9e87-401c83da435e',\n",
       " 'e7b23807-8cf0-11ee-9c55-401c83da435e',\n",
       " 'e7b23808-8cf0-11ee-b761-401c83da435e',\n",
       " 'e7b23809-8cf0-11ee-a15d-401c83da435e',\n",
       " 'e7b2380a-8cf0-11ee-90ab-401c83da435e',\n",
       " 'e7b2380b-8cf0-11ee-83fc-401c83da435e',\n",
       " 'e7b2380c-8cf0-11ee-b385-401c83da435e',\n",
       " 'e7b2380d-8cf0-11ee-bac8-401c83da435e',\n",
       " 'e7b2380e-8cf0-11ee-a31d-401c83da435e',\n",
       " 'e7b2380f-8cf0-11ee-ba9f-401c83da435e',\n",
       " 'e7b23810-8cf0-11ee-80e6-401c83da435e',\n",
       " 'e7b23811-8cf0-11ee-85f8-401c83da435e',\n",
       " 'e7b23812-8cf0-11ee-ae0f-401c83da435e',\n",
       " 'e7b23813-8cf0-11ee-b5c4-401c83da435e',\n",
       " 'e7b23814-8cf0-11ee-9986-401c83da435e',\n",
       " 'e7b23815-8cf0-11ee-ad74-401c83da435e',\n",
       " 'e7b23816-8cf0-11ee-b4ca-401c83da435e',\n",
       " 'e7b23817-8cf0-11ee-b23e-401c83da435e',\n",
       " 'e7b23818-8cf0-11ee-aac3-401c83da435e',\n",
       " 'e7b23819-8cf0-11ee-a804-401c83da435e',\n",
       " 'e7b2381a-8cf0-11ee-8012-401c83da435e',\n",
       " 'e7b2381b-8cf0-11ee-a729-401c83da435e',\n",
       " 'e7b2381c-8cf0-11ee-9f96-401c83da435e',\n",
       " 'e7b2381d-8cf0-11ee-b4fe-401c83da435e',\n",
       " 'e7b2381e-8cf0-11ee-b786-401c83da435e',\n",
       " 'e7b2381f-8cf0-11ee-9552-401c83da435e',\n",
       " 'e7b23820-8cf0-11ee-8f9c-401c83da435e',\n",
       " 'e7b23821-8cf0-11ee-aebc-401c83da435e',\n",
       " 'e7b23822-8cf0-11ee-94d0-401c83da435e',\n",
       " 'e7b23823-8cf0-11ee-ad08-401c83da435e',\n",
       " 'e7b23824-8cf0-11ee-b7b5-401c83da435e',\n",
       " 'e7b23825-8cf0-11ee-8407-401c83da435e',\n",
       " 'e7b23826-8cf0-11ee-8c3a-401c83da435e',\n",
       " 'e7b23827-8cf0-11ee-bab0-401c83da435e']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we add all the chunks to the Deep lake\n",
    "db.add_texts(all_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0a485",
   "metadata": {},
   "source": [
    "Since the dataset is stored on Activeloop, you can load it later without recomputing embeddings. This is a significant benefit cause it would save you time and computational resources. LangChain has a wrapper around Deep Lake, allowing you to use it as a Vector Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc6f0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#db = DeepLake(dataset_path=dataset_path,read_only=True,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c4a25",
   "metadata": {},
   "source": [
    "We are done with setting up the Deep Lake dataset with our documents! Let’s now focus on building the “Plan and Execute” agent that will leverage our dataset. Now, we can set up our Plan and Execute agent. Let’s create a retriever from the Deep Lake dataset and a function for our custom tool that retrieves the most similar documents to a query from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f87c6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the retriever object from the deep lake db object and set the number\n",
    "# of retrieved documents to 3\n",
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs['k'] = 3\n",
    "\n",
    "# We define some variables that will be used inside our custom tool\n",
    "CUSTOM_TOOL_DOCS_SEPARATOR =\"\\n---------------\\n\" # how to join together the retrieved docs to form a single string\n",
    "\n",
    "# This is the function that defines our custom tool that retrieves relevant\n",
    "# docs from Deep Lake\n",
    "def retrieve_n_docs_tool(query: str) -> str:\n",
    "    \"\"\"Searches for relevant documents that may contain the answer to the query.\"\"\"\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    texts = [doc.page_content for doc in docs]\n",
    "    texts_merged = \"---------------\\n\" + CUSTOM_TOOL_DOCS_SEPARATOR.join(texts) + \"\\n---------------\"\n",
    "    return texts_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c6b36",
   "metadata": {},
   "source": [
    "We retrieve the retriever object from the Deep Lake database and set the number of retrieved documents to 3. This is important for the plan and execution agent because it allows us to retrieve a specific number of relevant documents from Deep Lake based on a given query.\n",
    "\n",
    "Also, we defined a custom tool function called retrieve_n_docs_tool that takes a query as input and uses the retriever to search for relevant documents containing the answer to the query. \n",
    "\n",
    "The retrieved document texts are then merged using the CUSTOM_TOOL_DOCS_SEPARATOR variable, representing the separator string used to join the documents into a single string. The merged text is returned as the output of the custom tool function. \n",
    "\n",
    "This functionality enables the plan and execution agent to retrieve and process relevant documents for further analysis and decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9262432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.tools import Tool\n",
    "\n",
    "# We create the tool that uses the \"retrieve_n_docs_tool\" function\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search Private Docs\",\n",
    "        func=retrieve_n_docs_tool,\n",
    "        description=\"useful for when you need to answer questions about current events about Artificial Intelligence\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133353a",
   "metadata": {},
   "source": [
    "The tool is named \"Search Private Docs,\" and its functionality is based on the retrieve_n_docs_tool function. The purpose of this tool is to provide a way to search for and retrieve relevant documents from Deep Lake in order to answer questions about current events related to Artificial Intelligence. The tool is described as being useful in situations where there is a need to gather information and insights from private documents. \n",
    "\n",
    "We are now ready to create the agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d686c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "\n",
    "# let's create the Plan and Execute agent\n",
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "planner = load_chat_planner(model)\n",
    "executor = load_agent_executor(model, tools, verbose=True)\n",
    "agent = PlanAndExecute(planner=planner, executor=executor, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc300db3",
   "metadata": {},
   "source": [
    "The agent consists of two components: a planner and an executor. The planner is responsible for generating a plan based on the given input, and the executor executes the plan by interacting with the tools and external systems. The agent is set to be verbose, which means it will provide detailed information and logs during its operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7faa6a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new PlanAndExecute chain...\u001b[0m\n",
      "steps=[Step(value='Research and gather information on the current state of Artificial Intelligence (AI) regulations by governments in different countries.'), Step(value='Organize the information by country and categorize it based on the level of AI regulation.'), Step(value='Provide an overview of the AI regulations in each country, including any specific laws or policies that have been implemented.'), Step(value='Include information on the key areas covered by the regulations, such as data privacy, algorithmic transparency, liability, and ethical considerations.'), Step(value='Highlight any notable differences or similarities between the regulations in different countries.'), Step(value='Summarize the overall trends and developments in AI regulations globally.'), Step(value='Given the above steps taken, provide an overview of Artificial Intelligence regulations by governments by country. ')]\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": \"Artificial Intelligence regulations by governments in different countries\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "“US-based AI developers will likely steal a march on their European competitors given the news that the EU parliamentary committees have green-lit its groundbreaking AI Act, where AI systems will need to be categorised according to their potential for harm from the outset. The US tech approach is typically to experiment first and, once market and product fit is established, to retrofit to other markets and their regulatory framework. This approach fosters innovation whereas EU-based AI developers will need to take note of the new rules and develop systems and processes which may take the edge off their ability to innovate. The UK is adopting a similar approach to the US, although the proximity of the EU market means that UK-based developers are more likely to fall into step with the EU ruleset from the outset. However, the potential to experiment in a safe space – a regulatory sandbox – may prove very attractive.”\n",
      "---------------\n",
      "Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "The Internal Market Committee and the Civil Liberties Committee of the European Parliament have endorsed new transparency and risk-management rules for artificial intelligence systems known as the AI Act.\n",
      "\n",
      "This marks a major step in the development of AI regulation in Europe, as these are the first-ever rules for AI. The rules aim to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "After the vote, co-rapporteur Brando Benifei (S&D, Italy) said:\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe current state of Artificial Intelligence (AI) regulations by governments in different countries is as follows:\n",
      "\n",
      "In the European Union (EU), the EU parliamentary committees have recently approved the groundbreaking AI Act. This act categorizes AI systems based on their potential for harm and introduces transparency and risk-management rules. The aim is to ensure that AI systems are safe, transparent, traceable, and non-discriminatory. The UK, being part of the EU, is likely to align with these regulations as well.\n",
      "\n",
      "In the United States, the approach to AI regulation is typically more focused on experimentation and market fit before retrofitting to regulatory frameworks. This approach fosters innovation. However, there is no comprehensive federal AI regulation in place yet.\n",
      "\n",
      "It's important to note that regulations can vary across different countries and regions. It would be beneficial to research specific countries of interest to get a more detailed understanding of their AI regulations.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current state of AI regulations is as follows: In the EU, the AI Act has been approved, categorizing AI systems based on potential harm and introducing transparency and risk-management rules. The US has a more experimental approach, with no comprehensive federal AI regulation in place yet.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Research and gather information on the current state of Artificial Intelligence (AI) regulations by governments in different countries.\n",
      "\n",
      "Response: The current state of AI regulations is as follows: In the EU, the AI Act has been approved, categorizing AI systems based on potential harm and introducing transparency and risk-management rules. The US has a more experimental approach, with no comprehensive federal AI regulation in place yet.\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"AI regulations by country\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "“US-based AI developers will likely steal a march on their European competitors given the news that the EU parliamentary committees have green-lit its groundbreaking AI Act, where AI systems will need to be categorised according to their potential for harm from the outset. The US tech approach is typically to experiment first and, once market and product fit is established, to retrofit to other markets and their regulatory framework. This approach fosters innovation whereas EU-based AI developers will need to take note of the new rules and develop systems and processes which may take the edge off their ability to innovate. The UK is adopting a similar approach to the US, although the proximity of the EU market means that UK-based developers are more likely to fall into step with the EU ruleset from the outset. However, the potential to experiment in a safe space – a regulatory sandbox – may prove very attractive.”\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\n",
      "Ryan is a senior editor at TechForge Media with over a decade of experience covering the latest technology and interviewing leading industry figures. He can often be sighted at tech conferences with a strong coffee in one hand and a laptop in the other. If it's geeky, he’s probably into it. Find him on Twitter (@Gadget_Ry) or Mastodon (@gadgetry@techhub.social)\n",
      "\n",
      "The Internal Market Committee and the Civil Liberties Committee of the European Parliament have endorsed new transparency and risk-management rules for artificial intelligence systems known as the AI Act.\n",
      "\n",
      "This marks a major step in the development of AI regulation in Europe, as these are the first-ever rules for AI. The rules aim to ensure that AI systems are safe, transparent, traceable, and non-discriminatory.\n",
      "\n",
      "After the vote, co-rapporteur Brando Benifei (S&D, Italy) said:\n",
      "---------------\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3mBased on the information gathered from the search, here is the organized information by country and the level of AI regulation:\n",
      "\n",
      "1. European Union (EU):\n",
      "   - The EU has approved the AI Act, which categorizes AI systems based on potential harm.\n",
      "   - The AI Act introduces transparency and risk-management rules for AI systems.\n",
      "   - Exemptions are provided for research activities and AI components under open-source licenses.\n",
      "   - Regulatory sandboxes are promoted to test AI before deployment.\n",
      "   - Citizens have the right to file complaints about AI systems and receive explanations of decisions.\n",
      "   - The EU AI Office will monitor the implementation of the AI rulebook.\n",
      "\n",
      "2. United States (US):\n",
      "   - The US does not have comprehensive federal AI regulation in place yet.\n",
      "   - The US takes an experimental approach to AI development.\n",
      "   - Market and product fit is established first, followed by retrofitting to regulatory frameworks.\n",
      "   - This approach fosters innovation among US-based AI developers.\n",
      "\n",
      "3. United Kingdom (UK):\n",
      "   - The UK is adopting a similar approach to the US in terms of AI regulation.\n",
      "   - However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\n",
      "   - The UK also has the potential to experiment in a regulatory sandbox.\n",
      "\n",
      "Please note that this information is based on the search results and may not be exhaustive.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Organize the information by country and categorize it based on the level of AI regulation.\n",
      "\n",
      "Response: Based on the information gathered from the search, here is the organized information by country and the level of AI regulation:\n",
      "\n",
      "1. European Union (EU):\n",
      "   - The EU has approved the AI Act, which categorizes AI systems based on potential harm.\n",
      "   - The AI Act introduces transparency and risk-management rules for AI systems.\n",
      "   - Exemptions are provided for research activities and AI components under open-source licenses.\n",
      "   - Regulatory sandboxes are promoted to test AI before deployment.\n",
      "   - Citizens have the right to file complaints about AI systems and receive explanations of decisions.\n",
      "   - The EU AI Office will monitor the implementation of the AI rulebook.\n",
      "\n",
      "2. United States (US):\n",
      "   - The US does not have comprehensive federal AI regulation in place yet.\n",
      "   - The US takes an experimental approach to AI development.\n",
      "   - Market and product fit is established first, followed by retrofitting to regulatory frameworks.\n",
      "   - This approach fosters innovation among US-based AI developers.\n",
      "\n",
      "3. United Kingdom (UK):\n",
      "   - The UK is adopting a similar approach to the US in terms of AI regulation.\n",
      "   - However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\n",
      "   - The UK also has the potential to experiment in a regulatory sandbox.\n",
      "\n",
      "Please note that this information is based on the search results and may not be exhaustive.\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current state of AI regulations in different countries is as follows:\\n\\n1. European Union (EU):\\n   - The EU has approved the AI Act, which categorizes AI systems based on potential harm.\\n   - The AI Act introduces transparency and risk-management rules for AI systems.\\n   - Exemptions are provided for research activities and AI components under open-source licenses.\\n   - Regulatory sandboxes are promoted to test AI before deployment.\\n   - Citizens have the right to file complaints about AI systems and receive explanations of decisions.\\n   - The EU AI Office will monitor the implementation of the AI rulebook.\\n\\n2. United States (US):\\n   - The US does not have comprehensive federal AI regulation in place yet.\\n   - The US takes an experimental approach to AI development.\\n   - Market and product fit is established first, followed by retrofitting to regulatory frameworks.\\n   - This approach fosters innovation among US-based AI developers.\\n\\n3. United Kingdom (UK):\\n   - The UK is adopting a similar approach to the US in terms of AI regulation.\\n   - However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\\n   - The UK also has the potential to experiment in a regulatory sandbox.\\n\\nPlease note that this information is based on the search results and may not be exhaustive.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Provide an overview of the AI regulations in each country, including any specific laws or policies that have been implemented.\n",
      "\n",
      "Response: The current state of AI regulations in different countries is as follows:\n",
      "\n",
      "1. European Union (EU):\n",
      "   - The EU has approved the AI Act, which categorizes AI systems based on potential harm.\n",
      "   - The AI Act introduces transparency and risk-management rules for AI systems.\n",
      "   - Exemptions are provided for research activities and AI components under open-source licenses.\n",
      "   - Regulatory sandboxes are promoted to test AI before deployment.\n",
      "   - Citizens have the right to file complaints about AI systems and receive explanations of decisions.\n",
      "   - The EU AI Office will monitor the implementation of the AI rulebook.\n",
      "\n",
      "2. United States (US):\n",
      "   - The US does not have comprehensive federal AI regulation in place yet.\n",
      "   - The US takes an experimental approach to AI development.\n",
      "   - Market and product fit is established first, followed by retrofitting to regulatory frameworks.\n",
      "   - This approach fosters innovation among US-based AI developers.\n",
      "\n",
      "3. United Kingdom (UK):\n",
      "   - The UK is adopting a similar approach to the US in terms of AI regulation.\n",
      "   - However, the proximity of the EU market means that UK-based developers are more likely to align with the EU ruleset.\n",
      "   - The UK also has the potential to experiment in a regulatory sandbox.\n",
      "\n",
      "Please note that this information is based on the search results and may not be exhaustive.\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The current objective is to include information on the key areas covered by the AI regulations, such as data privacy, algorithmic transparency, liability, and ethical considerations. I can provide an overview of these key areas for each country mentioned in the previous steps.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Search Private Docs\",\n",
      "  \"action_input\": {\n",
      "    \"tool_input\": \"AI regulations key areas\"\n",
      "  }\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m---------------\n",
      "In a demo showcasing AIP, a military operator responsible for monitoring activity within Eastern Europe receives an alert that military equipment is amassed in a field 30km from friendly forces.\n",
      "\n",
      "AIP leverages large language models to allow operators to quickly ask questions such as:\n",
      "\n",
      "What enemy units are in the region?\n",
      "\n",
      "Task new imagery for this location at a resolution of one metre or higher\n",
      "\n",
      "Generate three courses of action to target this enemy equipment\n",
      "\n",
      "Analyse the battlefield, considering a Stryker vehicle and a platoon-size unit\n",
      "\n",
      "How many Javelin missiles does Team Omega have?\n",
      "\n",
      "Assign jammers to each of the validated high-priority communications targets\n",
      "\n",
      "Summarise the operational plan\n",
      "---------------\n",
      "To boost AI innovation, MEPs added exemptions to these rules for research activities and AI components provided under open-source licenses. The new law also promotes regulatory sandboxes – or controlled environments established by public authorities – to test AI before its deployment.\n",
      "\n",
      "MEPs want to boost citizens’ right to file complaints about AI systems and receive explanations of decisions based on high-risk AI systems that significantly impact their rights. MEPs also reformed the role of the EU AI Office, which would be tasked with monitoring how the AI rulebook is implemented.\n",
      "\n",
      "Tim Wright, Tech and AI Regulatory Partner at London-based law firm Fladgate, commented:\n",
      "---------------\n",
      "Summarise the operational plan\n",
      "\n",
      "As the operator poses questions, the LLM is using real-time information integrated from across public and classified sources. Data is automatically tagged and protected by classification markings, and AIP enforces which parts of the organisation the LLM has access to while respecting an individual’s permissions, role, and need to know.\n",
      "\n",
      "Every response from AIP retains links back to the underlying data records to enable transparency for the user who can investigate as necessary.\n",
      "\n",
      "AIP unleashes the power of large language models and cutting-edge AI for defense and military organisations while aiming to do so with the appropriate guardrails and high levels of ethics and transparency that are required for such sensitive applications.\n",
      "\n",
      "﻿\n",
      "\n",
      "(Image Credit: Palantir)\n",
      "---------------\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3mThe search in the private documents did not provide any relevant information on the key areas covered by AI regulations, such as data privacy, algorithmic transparency, liability, and ethical considerations. However, based on general knowledge, these key areas are often addressed in AI regulations. Data privacy regulations aim to protect personal data and ensure that AI systems handle data in a secure and responsible manner. Algorithmic transparency refers to the requirement for AI systems to provide explanations or justifications for their decisions or actions. Liability regulations determine who is responsible if an AI system causes harm or makes a mistake. Ethical considerations in AI regulations involve promoting fairness, accountability, and avoiding bias in AI systems.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "*****\n",
      "\n",
      "Step: Include information on the key areas covered by the regulations, such as data privacy, algorithmic transparency, liability, and ethical considerations.\n",
      "\n",
      "Response: The search in the private documents did not provide any relevant information on the key areas covered by AI regulations, such as data privacy, algorithmic transparency, liability, and ethical considerations. However, based on general knowledge, these key areas are often addressed in AI regulations. Data privacy regulations aim to protect personal data and ensure that AI systems handle data in a secure and responsible manner. Algorithmic transparency refers to the requirement for AI systems to provide explanations or justifications for their decisions or actions. Liability regulations determine who is responsible if an AI system causes harm or makes a mistake. Ethical considerations in AI regulations involve promoting fairness, accountability, and avoiding bias in AI systems.\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-k9LQtZKllzwGlzidOA94QWrY on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# we test the agent\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite an overview of Artificial Intelligence regulations by governments by country\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\base.py:505\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    506\u001b[0m         _output_key\n\u001b[0;32m    507\u001b[0m     ]\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    511\u001b[0m         _output_key\n\u001b[0;32m    512\u001b[0m     ]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    311\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    312\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    314\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    298\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    299\u001b[0m     inputs,\n\u001b[0;32m    300\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 304\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain_experimental\\plan_and_execute\\agent_executor.py:56\u001b[0m, in \u001b[0;36mPlanAndExecute._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     50\u001b[0m _new_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprevious_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_container,\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_step\u001b[39m\u001b[38;5;124m\"\u001b[39m: step,\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key],\n\u001b[0;32m     54\u001b[0m }\n\u001b[0;32m     55\u001b[0m new_inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_new_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs}\n\u001b[1;32m---> 56\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mstep(\n\u001b[0;32m     57\u001b[0m     new_inputs,\n\u001b[0;32m     58\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager:\n\u001b[0;32m     61\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_text(\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*****\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose\n\u001b[0;32m     63\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain_experimental\\plan_and_execute\\executors\\base.py:37\u001b[0m, in \u001b[0;36mChainExecutor.step\u001b[1;34m(self, inputs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m, inputs: \u001b[38;5;28mdict\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StepResponse:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Take step.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StepResponse(response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\base.py:510\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    506\u001b[0m         _output_key\n\u001b[0;32m    507\u001b[0m     ]\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m--> 510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[0;32m    511\u001b[0m         _output_key\n\u001b[0;32m    512\u001b[0m     ]\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    518\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    311\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    312\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    314\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    298\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    299\u001b[0m     inputs,\n\u001b[0;32m    300\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 304\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\agents\\agent.py:1245\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1245\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_next_step(\n\u001b[0;32m   1246\u001b[0m         name_to_tool_map,\n\u001b[0;32m   1247\u001b[0m         color_mapping,\n\u001b[0;32m   1248\u001b[0m         inputs,\n\u001b[0;32m   1249\u001b[0m         intermediate_steps,\n\u001b[0;32m   1250\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1251\u001b[0m     )\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1253\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1254\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[0;32m   1255\u001b[0m         )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\agents\\agent.py:1032\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1029\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[0;32m   1031\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m-> 1032\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mplan(\n\u001b[0;32m   1033\u001b[0m         intermediate_steps,\n\u001b[0;32m   1034\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1035\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m   1036\u001b[0m     )\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\agents\\agent.py:635\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[0;32m    624\u001b[0m \n\u001b[0;32m    625\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;124;03m    Action specifying what tool to use.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    634\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 635\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mparse(full_output)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\llm.py:298\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[1;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    284\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    311\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    312\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    314\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    297\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[0;32m    298\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    299\u001b[0m     inputs,\n\u001b[0;32m    300\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[0;32m    301\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 304\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    307\u001b[0m     )\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\llm.py:108\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    105\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    106\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    107\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 108\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chains\\llm.py:120\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    118\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    121\u001b[0m         prompts,\n\u001b[0;32m    122\u001b[0m         stop,\n\u001b[0;32m    123\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    125\u001b[0m     )\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    128\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    129\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chat_models\\base.py:459\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    458\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chat_models\\base.py:349\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    348\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    350\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    351\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    353\u001b[0m ]\n\u001b[0;32m    354\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chat_models\\base.py:339\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 339\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    340\u001b[0m                 m,\n\u001b[0;32m    341\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    342\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    343\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    344\u001b[0m             )\n\u001b[0;32m    345\u001b[0m         )\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chat_models\\base.py:492\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    489\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    493\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    494\u001b[0m     )\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chat_models\\openai.py:422\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    421\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 422\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    423\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    424\u001b[0m )\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\langchain\\chat_models\\openai.py:344\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    346\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(\u001b[38;5;28mself\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\openai\\_utils\\_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:598\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    596\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    600\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    601\u001b[0m             {\n\u001b[0;32m    602\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m    603\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    604\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m    605\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m    606\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m    607\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m    608\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m    609\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    610\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m    611\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    612\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m    613\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m    614\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m    615\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m    616\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m    617\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m    618\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m    619\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    620\u001b[0m             },\n\u001b[0;32m    621\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m    622\u001b[0m         ),\n\u001b[0;32m    623\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    624\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    625\u001b[0m         ),\n\u001b[0;32m    626\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m    627\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    628\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mStream[ChatCompletionChunk],\n\u001b[0;32m    629\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\openai\\_base_client.py:1055\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1043\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1051\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1052\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1053\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1054\u001b[0m     )\n\u001b[1;32m-> 1055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\openai\\_base_client.py:834\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    827\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    832\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    833\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    835\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    836\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    837\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    838\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    839\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    840\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\openai\\_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m--> 865\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m    866\u001b[0m             options,\n\u001b[0;32m    867\u001b[0m             cast_to,\n\u001b[0;32m    868\u001b[0m             retries,\n\u001b[0;32m    869\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    870\u001b[0m             stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    871\u001b[0m             stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    872\u001b[0m         )\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\openai\\_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    926\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    927\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    928\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m    929\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    930\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    931\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\openai\\_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m--> 865\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m    866\u001b[0m             options,\n\u001b[0;32m    867\u001b[0m             cast_to,\n\u001b[0;32m    868\u001b[0m             retries,\n\u001b[0;32m    869\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    870\u001b[0m             stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    871\u001b[0m             stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    872\u001b[0m         )\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\openai\\_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    926\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    927\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    928\u001b[0m     remaining_retries\u001b[38;5;241m=\u001b[39mremaining,\n\u001b[0;32m    929\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    930\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    931\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3b\\envs\\env_llm\\Lib\\site-packages\\openai\\_base_client.py:877\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    874\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 877\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-k9LQtZKllzwGlzidOA94QWrY on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# we test the agent\n",
    "response = agent.run(\"Write an overview of Artificial Intelligence regulations by governments by country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f22e55",
   "metadata": {},
   "source": [
    "At first, the planning agent creates a plan for our query with multiple steps. Each step is a query that the action agent will be asked to give an answer to. Here are the identified steps.\n",
    "\n",
    "    Research the current state of Artificial Intelligence (AI) regulations in various countries.\n",
    "    Identify the key countries with significant AI regulations or ongoing discussions about AI regulations.\n",
    "    Summarize the AI regulations or discussions in each identified country.\n",
    "    Organize the information by country, providing an overview of each AI regulation.\n",
    "    Given the above steps taken, provide an overview of Artificial Intelligence regulations by governments by country.\n",
    "\n",
    "Then, we see the executor agent searching for relevant documents with our Deep Lake tool and showing the top 3 retrieved chunks. After analyzing them, the agent decides to return the final answer to the question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd202a",
   "metadata": {},
   "source": [
    "Let’s print the final response from the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a8a077c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European Union: The AI Act has been endorsed by the Internal Market Committee and the Civil Liberties Committee, aiming to ensure AI systems are safe, transparent, traceable, and non-discriminatory. United States: AI developers typically experiment first and then retrofit their products to other markets and regulatory frameworks, fostering innovation. United Kingdom: The UK is adopting a similar approach to the US, but its proximity to the EU market means that UK-based developers are more likely to align with the EU ruleset from the outset. Regulatory sandboxes are being promoted to test AI before deployment.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0ca36",
   "metadata": {},
   "source": [
    "We see that the agent has been able to iteratively create an overview of AI regulations by diverse documents, leveraging several documents.\n",
    "\n",
    "The experiment involving the Plan and Execute agent has been successful in providing a comprehensive overview of Artificial Intelligence regulations by governments, specifically by finding information about the European Union, United States, and United Kingdom. The agent effectively performed various steps, including researching the current state of AI regulations, identifying key countries, summarizing regulations, and organizing the information by country.\n",
    "\n",
    "The output generated by the agent demonstrates its ability to understand and interpret complex information about AI regulations. It accurately summarizes the AI regulations in each country, highlighting the endorsement of the AI Act in the European Union to ensure the safety, transparency, traceability, and non-discrimination of AI systems.\n",
    "\n",
    "The agent successfully executes its plan by retrieving relevant information, summarizing it, and providing a concise and informative overview. It demonstrates its capability to gather insights from multiple sources and deliver a coherent response. The agent's performance in this experiment highlights its potential to assist with research, generate informative summaries, and provide valuable insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_llm",
   "language": "python",
   "name": "env_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
